{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bc43b9-a98e-4513-86fd-c7dcb1fe166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal\\anaconda3\\envs\\accentid\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f1a0cd-c1a6-4ee2-910e-7173aa0bee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656b039f-71d4-491b-a1ba-c60748aef5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"C:\\Users\\Kushal\\OneDrive - Vasavi College Of Engineering\\Desktop\\Kushal\\Studies\\IIITH RI\\final_project\\datasets\"  # ← UPDATE THIS PATH\n",
    "\n",
    "label_map = {\n",
    "    \"andhra_pradesh\": \"telugu\",\n",
    "    \"gujrat\": \"gujarati\",\n",
    "    \"jharkhand\": \"hindi\",\n",
    "    \"karnataka\": \"kannada\",\n",
    "    \"kerala\": \"malayalam\",\n",
    "    \"tamil\": \"tamil\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fa20a9-d9a2-4c99-a647-1d746509f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio samples: 8116\n",
      "Example: C:\\Users\\Kushal\\OneDrive - Vasavi College Of Engineering\\Desktop\\Kushal\\Studies\\IIITH RI\\final_project\\datasets\\andhra_pradesh\\Andhra_speaker (1).wav → telugu\n"
     ]
    }
   ],
   "source": [
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for region_folder in os.listdir(DATASET_PATH):\n",
    "    folder_path = os.path.join(DATASET_PATH, region_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        language_label = label_map.get(region_folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_files.append(os.path.join(folder_path, file))\n",
    "                labels.append(language_label)\n",
    "\n",
    "print(\"Total audio samples:\", len(audio_files))\n",
    "print(\"Example:\", audio_files[0], \"→\", labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a5b713-cca6-4855-8afc-f5bc19abb356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['gujarati' 'hindi' 'kannada' 'malayalam' 'tamil' 'telugu']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "print(\"Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef114cba-12fe-40b0-b159-5386b140dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40, max_len=200):\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Normalize length by padding/truncation → fixed shape\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad8f1dd-d7c9-45bf-ba17-a70a882a978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MFCC features already extracted. Loading from cache...\n",
      "MFCC feature shape: (8116, 40, 200)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mfcc_cache = \"mfcc_features.npy\"\n",
    "label_cache = \"labels.npy\"\n",
    "\n",
    "if os.path.exists(mfcc_cache) and os.path.exists(label_cache):\n",
    "    print(\"✅ MFCC features already extracted. Loading from cache...\")\n",
    "    X = np.load(mfcc_cache)\n",
    "    y = np.load(label_cache)\n",
    "else:\n",
    "    print(\"⏳ Extracting MFCC features... (one-time operation)\")\n",
    "    X = []\n",
    "    for f in tqdm(audio_files):\n",
    "        mfcc = extract_mfcc(f)\n",
    "        X.append(mfcc)\n",
    "    X = np.array(X)\n",
    "    y = np.array(encoded_labels)\n",
    "\n",
    "    np.save(mfcc_cache, X)\n",
    "    np.save(label_cache, y)\n",
    "\n",
    "print(\"MFCC feature shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c57e6c-7b49-467e-b7f6-f5ed1bc3ca3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6492, 40, 200)  Test: (1624, 40, 200)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82adf17d-f035-431b-9bbb-38d3221d1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9901477832512315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    gujarati       1.00      0.97      0.98        60\n",
      "       hindi       1.00      0.98      0.99       166\n",
      "     kannada       1.00      0.99      1.00       337\n",
      "   malayalam       0.99      0.99      0.99       334\n",
      "       tamil       0.99      0.99      0.99       368\n",
      "      telugu       0.98      0.99      0.98       359\n",
      "\n",
      "    accuracy                           0.99      1624\n",
      "   macro avg       0.99      0.99      0.99      1624\n",
      "weighted avg       0.99      0.99      0.99      1624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_flat = X_train.reshape(len(X_train), -1)\n",
    "X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_flat)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "284bfd0e-ab2f-4d9e-a12a-b31c4232e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal\\anaconda3\\envs\\accentid\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import HubertModel, AutoFeatureExtractor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using:\", device)\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "hubert = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1916accc-05f7-4349-8bae-562e1059e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hubert_embedding(file_path):\n",
    "    # Load audio\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "\n",
    "    # If stereo → convert to mono by averaging channels\n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "    # Resample to 16000 Hz if needed\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        audio = resampler(audio)\n",
    "\n",
    "    audio = audio.squeeze()  # shape: (samples,)\n",
    "\n",
    "    # Prepare input for HuBERT\n",
    "    inputs = feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = hubert(**inputs)\n",
    "        hidden_states = outputs.last_hidden_state  # (1, frames, 768)\n",
    "\n",
    "    # Mean pooling across time frames → (768,)\n",
    "    embedding = hidden_states.mean(dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2434efe1-28a0-4e82-bc29-10cea6207b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = extract_hubert_embedding(audio_files[0])\n",
    "emb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c8bb59-cc8a-4419-80f6-ec6983cffbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HuBERT embeddings already extracted. Loading from cache...\n",
      "HuBERT feature matrix: (8116, 768)\n"
     ]
    }
   ],
   "source": [
    "hubert_cache = \"hubert_features.npy\"\n",
    "\n",
    "if os.path.exists(hubert_cache):\n",
    "    print(\"✅ HuBERT embeddings already extracted. Loading from cache...\")\n",
    "    hubert_features = np.load(hubert_cache)\n",
    "else:\n",
    "    print(\"⏳ Extracting HuBERT embeddings... (this is the heavy step, only once)\")\n",
    "    hubert_features = []\n",
    "    for f in tqdm(audio_files):\n",
    "        emb = extract_hubert_embedding(f)\n",
    "        hubert_features.append(emb)\n",
    "\n",
    "    hubert_features = np.array(hubert_features)\n",
    "    np.save(hubert_cache, hubert_features)\n",
    "\n",
    "print(\"HuBERT feature matrix:\", hubert_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac802d8c-0d1e-426c-ab7a-c0b678050f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6492, 768) Test: (1624, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    hubert_features, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train_h.shape, \"Test:\", X_test_h.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ea1782-e273-4d4f-8cb7-afe45e4dabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1, 768)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               918528    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952198 (3.63 MB)\n",
      "Trainable params: 952198 (3.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, Reshape\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "model = Sequential([\n",
    "    Reshape((1, 768), input_shape=(768,)),       # convert vector to sequence of length 1\n",
    "    Bidirectional(LSTM(128, return_sequences=False)),\n",
    "    Dropout(0.35),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393c93fb-b401-4b69-8fb3-70ab002c1861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.26.4\n",
      "TF: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"TF:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "251a6ea6-f957-4d36-b2d0-dd8bc448f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "203/203 [==============================] - 6s 15ms/step - loss: 0.5917 - accuracy: 0.7904 - val_loss: 0.1145 - val_accuracy: 0.9624\n",
      "Epoch 2/8\n",
      "203/203 [==============================] - 2s 12ms/step - loss: 0.0904 - accuracy: 0.9729 - val_loss: 0.0521 - val_accuracy: 0.9840\n",
      "Epoch 3/8\n",
      "203/203 [==============================] - 2s 12ms/step - loss: 0.0578 - accuracy: 0.9821 - val_loss: 0.0457 - val_accuracy: 0.9846\n",
      "Epoch 4/8\n",
      "203/203 [==============================] - 2s 12ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0567 - val_accuracy: 0.9846\n",
      "Epoch 5/8\n",
      "203/203 [==============================] - 2s 12ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.0475 - val_accuracy: 0.9858\n",
      "Epoch 6/8\n",
      "203/203 [==============================] - 2s 12ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0346 - val_accuracy: 0.9901\n",
      "Epoch 7/8\n",
      "203/203 [==============================] - 3s 12ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0309 - val_accuracy: 0.9932\n",
      "Epoch 8/8\n",
      "203/203 [==============================] - 3s 12ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0385 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_h, y_train_h,\n",
    "    validation_data=(X_test_h, y_test_h),\n",
    "    epochs=8,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c5bb856-63d2-49ee-a4df-f0a52851375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 4ms/step\n",
      "BiLSTM Accuracy: 0.9926108374384236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    gujarati       1.00      1.00      1.00        60\n",
      "       hindi       0.99      1.00      0.99       166\n",
      "     kannada       0.99      1.00      1.00       337\n",
      "   malayalam       0.99      0.99      0.99       334\n",
      "       tamil       1.00      0.99      0.99       368\n",
      "      telugu       0.99      0.99      0.99       359\n",
      "\n",
      "    accuracy                           0.99      1624\n",
      "   macro avg       0.99      0.99      0.99      1624\n",
      "weighted avg       0.99      0.99      0.99      1624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test_h)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"BiLSTM Accuracy:\", accuracy_score(y_test_h, y_pred))\n",
    "print(classification_report(y_test_h, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eb14593-a9c3-47d8-b199-c0c07f8a1f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult samples: 8116\n",
      "Child samples: 0\n"
     ]
    }
   ],
   "source": [
    "adult_files = []\n",
    "child_files = []\n",
    "adult_labels = []\n",
    "child_labels = []\n",
    "\n",
    "for file, lbl in zip(audio_files, labels):\n",
    "    name = os.path.basename(file).lower()\n",
    "    if \"child\" in name:\n",
    "        child_files.append(file)\n",
    "        child_labels.append(lbl)\n",
    "    else:\n",
    "        adult_files.append(file)\n",
    "        adult_labels.append(lbl)\n",
    "\n",
    "print(\"Adult samples:\", len(adult_files))\n",
    "print(\"Child samples:\", len(child_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768e739e-c147-4fe5-9eed-5e70e08d465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word samples: 730\n",
      "Sentence samples: 7386\n"
     ]
    }
   ],
   "source": [
    "word_files = []\n",
    "sentence_files = []\n",
    "word_labels = []\n",
    "sentence_labels = []\n",
    "\n",
    "for f, lbl in zip(audio_files, labels):\n",
    "    audio, sr = librosa.load(f, sr=16000)\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "\n",
    "    if duration < 2.5:\n",
    "        word_files.append(f)\n",
    "        word_labels.append(lbl)\n",
    "    else:\n",
    "        sentence_files.append(f)\n",
    "        sentence_labels.append(lbl)\n",
    "\n",
    "print(\"Word samples:\", len(word_files))\n",
    "print(\"Sentence samples:\", len(sentence_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb6a77d-cb1d-4556-981f-b9a8c0079b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word-level HuBERT embeddings already cached. Loading...\n",
      "✅ Sentence-level HuBERT embeddings already cached. Loading...\n",
      "Word Embeddings: (730, 768)\n",
      "Sentence Embeddings: (7386, 768)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "word_cache = \"word_hubert_features.npy\"\n",
    "word_label_cache = \"word_labels.npy\"\n",
    "sentence_cache = \"sentence_hubert_features.npy\"\n",
    "sentence_label_cache = \"sentence_labels.npy\"\n",
    "\n",
    "# WORD FEATURES\n",
    "if os.path.exists(word_cache) and os.path.exists(word_label_cache):\n",
    "    print(\"✅ Word-level HuBERT embeddings already cached. Loading...\")\n",
    "    word_emb = np.load(word_cache)\n",
    "    word_labels_enc = np.load(word_label_cache)\n",
    "else:\n",
    "    print(\"⏳ Extracting word-level embeddings... (one-time operation)\")\n",
    "    word_emb = np.array([extract_hubert_embedding(f) for f in tqdm(word_files)])\n",
    "    word_labels_enc = le.transform(word_labels)\n",
    "\n",
    "    np.save(word_cache, word_emb)\n",
    "    np.save(word_label_cache, word_labels_enc)\n",
    "    print(\"✅ Saved word-level embeddings for future reuse.\")\n",
    "\n",
    "# SENTENCE FEATURES\n",
    "if os.path.exists(sentence_cache) and os.path.exists(sentence_label_cache):\n",
    "    print(\"✅ Sentence-level HuBERT embeddings already cached. Loading...\")\n",
    "    sentence_emb = np.load(sentence_cache)\n",
    "    sentence_labels_enc = np.load(sentence_label_cache)\n",
    "else:\n",
    "    print(\"⏳ Extracting sentence-level embeddings... (one-time operation)\")\n",
    "    sentence_emb = np.array([extract_hubert_embedding(f) for f in tqdm(sentence_files)])\n",
    "    sentence_labels_enc = le.transform(sentence_labels)\n",
    "\n",
    "    np.save(sentence_cache, sentence_emb)\n",
    "    np.save(sentence_label_cache, sentence_labels_enc)\n",
    "    print(\"✅ Saved sentence-level embeddings for future reuse.\")\n",
    "\n",
    "print(\"Word Embeddings:\", word_emb.shape)\n",
    "print(\"Sentence Embeddings:\", sentence_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a019d979-7424-4b4a-b65e-bb270ba97e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step\n",
      "231/231 [==============================] - 1s 4ms/step\n",
      "Word Accuracy: 0.9945205479452055\n",
      "Sentence Accuracy: 0.9983753046303818\n"
     ]
    }
   ],
   "source": [
    "word_preds = np.argmax(model.predict(word_emb), axis=1)\n",
    "sentence_preds = np.argmax(model.predict(sentence_emb), axis=1)\n",
    "\n",
    "print(\"Word Accuracy:\", accuracy_score(word_labels_enc, word_preds))\n",
    "print(\"Sentence Accuracy:\", accuracy_score(sentence_labels_enc, sentence_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50afaf6a-4240-4564-8255-2bd51a85bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique speakers: 7\n"
     ]
    }
   ],
   "source": [
    "def get_speaker_id(path):\n",
    "    name = os.path.basename(path)\n",
    "    # remove extension\n",
    "    name = name.split(\".\")[0]\n",
    "    # split on space / underscore / parenthesis\n",
    "    for sep in [\"(\", \"_\", \"-\"]:\n",
    "        name = name.split(sep)[0]\n",
    "    return name.lower().strip()\n",
    "\n",
    "speaker_ids = [get_speaker_id(f) for f in audio_files]\n",
    "\n",
    "print(\"Unique speakers:\", len(set(speaker_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d67fd794-c2cd-42c4-88d3-cf517fef458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted Accent: malayalam\n"
     ]
    }
   ],
   "source": [
    "test_file = audio_files[5678]   # or any path\n",
    "\n",
    "emb = extract_hubert_embedding(test_file)\n",
    "emb = emb.reshape(1, -1)\n",
    "pred = np.argmax(model.predict(emb), axis=1)\n",
    "print(\"Predicted Accent:\", le.inverse_transform(pred)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaa72982-8219-4be5-a485-8e4ceb4a7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kushal\\anaconda3\\envs\\accentid\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All model components saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Paths for saved artifacts\n",
    "MODEL_PATH = \"accent_bilstm_model.h5\"\n",
    "ENCODER_PATH = \"label_encoder.pkl\"\n",
    "HISTORY_PATH = \"train_history.pkl\"\n",
    "MFCC_PATH = \"mfcc_features.npy\"\n",
    "HUBERT_PATH = \"hubert_features.npy\"\n",
    "LABELS_PATH = \"labels.npy\"\n",
    "\n",
    "# ----------------------------\n",
    "# SAVE SECTION\n",
    "# ----------------------------\n",
    "\n",
    "# Save trained model\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "# Save label encoder\n",
    "with open(ENCODER_PATH, \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "# Save training history\n",
    "with open(HISTORY_PATH, \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# Save feature matrices (only if they exist in memory)\n",
    "if 'X' in globals():\n",
    "    np.save(MFCC_PATH, X)\n",
    "if 'hubert_features' in globals():\n",
    "    np.save(HUBERT_PATH, hubert_features)\n",
    "if 'y' in globals():\n",
    "    np.save(LABELS_PATH, y)\n",
    "\n",
    "print(\"✅ All model components saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9da3807-1f2c-4083-97c4-736cee76f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model, encoder, features, and history loaded successfully.\n",
      "Feature shapes: (8116, 40, 200) (8116, 768)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_PATH = \"accent_bilstm_model.h5\"\n",
    "ENCODER_PATH = \"label_encoder.pkl\"\n",
    "HISTORY_PATH = \"train_history.pkl\"\n",
    "MFCC_PATH = \"mfcc_features.npy\"\n",
    "HUBERT_PATH = \"hubert_features.npy\"\n",
    "LABELS_PATH = \"labels.npy\"\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Load label encoder\n",
    "with open(ENCODER_PATH, \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "# Load history\n",
    "with open(HISTORY_PATH, \"rb\") as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "# Load cached features\n",
    "X = np.load(MFCC_PATH)\n",
    "hubert_features = np.load(HUBERT_PATH)\n",
    "y = np.load(LABELS_PATH)\n",
    "\n",
    "print(\"✅ Model, encoder, features, and history loaded successfully.\")\n",
    "print(\"Feature shapes:\", X.shape, hubert_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbf134-767c-40c6-896a-aace59101e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AccentID Env",
   "language": "python",
   "name": "accentid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
